{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "nTwZ2mbCgfqV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from itertools import combinations"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from file\n",
        "def load(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    data = [list(map(int, line.strip().replace(\" \", \"\").replace(\"\\xa0\", \"\"))) for line in lines]\n",
        "    data = pd.DataFrame(data)\n",
        "    return data.iloc[:, :-1], data.iloc[:, -1]"
      ],
      "metadata": {
        "id": "T-G47za1xyDW"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to map the raw input data into the required features\n",
        "def my_map(x_raw):\n",
        "    if isinstance(x_raw, pd.DataFrame):\n",
        "        x_raw = x_raw.values\n",
        "    if x_raw.shape[1] != 8:\n",
        "        raise ValueError(\"Input must have 8 features.\")\n",
        "\n",
        "    x_mapped = 1 - 2 * x_raw  # Mapping 0->1, 1->-1\n",
        "    n_samples = x_mapped.shape[0]\n",
        "\n",
        "    # Prepare array: bias + 8 linear + 7 cumulative + 105 (14+13+..+1) quadratic = 121\n",
        "    psi = np.ones((n_samples, 121), dtype=np.int8)\n",
        "\n",
        "    # Linear features\n",
        "    psi[:, 1:9] = x_mapped\n",
        "\n",
        "    # Cumulative features (excluding first)\n",
        "    cum_features = np.empty((n_samples, 7), dtype=np.int8)\n",
        "    for i in range(n_samples):\n",
        "        cumprod = np.cumprod(x_mapped[i])\n",
        "        cum_features[i] = cumprod[1:9]  # x0*x1, x0*x1*x2, ..., x0*x1*...*x6\n",
        "        psi[i, 9:16] = cum_features[i]\n",
        "\n",
        "    # Quadratic features of linear + cumulative (15 choose 2 = 105)\n",
        "    combined = np.concatenate([x_mapped, cum_features], axis=1)  # shape (n_samples, 15)\n",
        "\n",
        "    idx = 16\n",
        "    for i, j in combinations(range(15), 2):\n",
        "        psi[:, idx] = combined[:, i] * combined[:, j]\n",
        "        idx += 1\n",
        "\n",
        "    return psi"
      ],
      "metadata": {
        "id": "thqA91sYSkim"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_fit(X_train, y_train, X_test, y_test):\n",
        "    # Scaling the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    model = LogisticRegression(max_iter=100, C=0.01, solver='liblinear', random_state=50)\n",
        "    start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    duration = time.time() - start\n",
        "\n",
        "    # Make predictions on the test data\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_test, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    # Print out evaluation metrics\n",
        "    print(f\"Training Time: {duration:.4f} sec\")\n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(f\"          Pred 0 | Pred 1\")\n",
        "    print(f\"Actual 0 | {cm[0][0]:^7} | {cm[0][1]:^7}\")\n",
        "    print(f\"Actual 1 | {cm[1][0]:^7} | {cm[1][1]:^7}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred, target_names=['Class 0', 'Class 1'], zero_division=0))\n",
        "\n",
        "    # Return the model and metrics\n",
        "    return model, {'accuracy': acc, 'precision': prec, 'recall': rec, 'f1': f1, 'training_time': duration}\n"
      ],
      "metadata": {
        "id": "aaXOA4mJkA4V"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to decode the model's weights into the original features\n",
        "def my_decode(w):\n",
        "    # Decode a 65-dimensional vector into four 64-dimensional vectors\n",
        "    # Assuming the first 4 parts of the weight vector correspond to p, q, r, s\n",
        "    p = w[:64]\n",
        "    q = w[64:]\n",
        "    r = np.zeros(64)  # Placeholder, modify as necessary\n",
        "    s = np.zeros(64)  # Placeholder, modify as necessary\n",
        "    return p, q, r, s"
      ],
      "metadata": {
        "id": "lubvmLpqcVrr"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main script\n",
        "print(\"Loading data...\")\n",
        "try:\n",
        "    x_train_raw, y_train = load(\"public_trn.txt\")\n",
        "    x_test_raw, y_test = load(\"public_tst.txt\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Missing data files.\")\n",
        "    exit()\n",
        "\n",
        "print(\"Mapping features...\")\n",
        "x_train = my_map(x_train_raw)\n",
        "x_test = my_map(x_test_raw)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")\n",
        "model, metrics = my_fit(x_train, y_train, x_test, y_test)\n",
        "\n",
        "print(f\"\\nFinal Test Accuracy: {metrics['accuracy']:.4f}\")"
      ],
      "metadata": {
        "id": "fs9bEYbYBPx1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29cddaf6-09c2-46c8-f05d-967b6b4892bb"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data...\n",
            "Mapping features...\n",
            "Train shape: (6400, 121), Test shape: (1600, 121)\n",
            "Training Time: 0.0839 sec\n",
            "Accuracy:  0.9263\n",
            "Precision: 0.8829\n",
            "Recall:    0.8829\n",
            "F1-Score:  0.8829\n",
            "\n",
            "Confusion Matrix:\n",
            "          Pred 0 | Pred 1\n",
            "Actual 0 |  1037   |   59   \n",
            "Actual 1 |   59    |   445  \n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.95      0.95      0.95      1096\n",
            "     Class 1       0.88      0.88      0.88       504\n",
            "\n",
            "    accuracy                           0.93      1600\n",
            "   macro avg       0.91      0.91      0.91      1600\n",
            "weighted avg       0.93      0.93      0.93      1600\n",
            "\n",
            "\n",
            "Final Test Accuracy: 0.9263\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfkBRtTHkG-l"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0HOKNeM54rk_"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UBBxMpzy8eix"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U61HLN-WCOIM"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3RpxKAkCN9R"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sEtti3Br8jK1"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-U6DRERcIuzG"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ub_6oW_zP46j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}